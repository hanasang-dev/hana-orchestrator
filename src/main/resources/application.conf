ktor {
    deployment {
        port = 8080
        port = ${?PORT}
    }
    
    application {
        modules = [ com.hana.orchestrator.ApplicationKt.main ]
    }
}

# LLM 설정
llm {
    # 간단한 작업용 모델 (validateQueryFeasibility, extractParameters)
    simple {
        modelId = "qwen3:8b"
        modelId = ${?LLM_SIMPLE_MODEL}
        contextLength = 40960
        contextLength = ${?LLM_SIMPLE_CONTEXT}
    }
    
    # 중간 작업용 모델 (evaluateResult, compareExecutions)
    medium {
        modelId = "qwen3:8b"
        modelId = ${?LLM_MEDIUM_MODEL}
        contextLength = 40960
        contextLength = ${?LLM_MEDIUM_CONTEXT}
    }
    
    # 복잡한 작업용 모델 (createExecutionTree, suggestRetryStrategy)
    complex {
        modelId = "qwen3:8b"
        modelId = ${?LLM_COMPLEX_MODEL}
        contextLength = 40960
        contextLength = ${?LLM_COMPLEX_CONTEXT}
    }
    
    # 공통 설정
    timeoutMs = 120000
    timeoutMs = ${?LLM_TIMEOUT_MS}
}

# 향후 API 키 등 민감한 정보는 환경변수로만 설정
# 예: OPENAI_API_KEY, ANTHROPIC_API_KEY 등
