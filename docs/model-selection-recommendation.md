# 모델 선택 추천 (2026년 기준)

## 작업별 특성 분석

### SIMPLE 작업
**작업**: `validateQueryFeasibility`, `extractParameters`
**특성**:
- 짧은 프롬프트 (100-500 토큰)
- 구조화된 JSON 출력 (간단한 스키마)
- 빠른 응답 필요 (실시간 처리)
- 높은 빈도 호출 (모든 요청마다 실행)

**요구사항**:
- 빠른 추론 속도
- 정확한 JSON 형식 준수
- 낮은 리소스 사용

### MEDIUM 작업
**작업**: `evaluateResult`, `compareExecutions`
**특성**:
- 중간 프롬프트 (500-2000 토큰)
- 판단과 비교 작업
- 중간 빈도 호출

**요구사항**:
- 좋은 판단 능력
- 컨텍스트 이해
- 균형잡힌 성능/속도

### COMPLEX 작업
**작업**: `createExecutionTree`, `suggestRetryStrategy`
**특성**:
- 긴 프롬프트 (2000-8000+ 토큰)
- 복잡한 추론과 계획 수립
- 많은 컨텍스트 처리
- 낮은 빈도 호출 (하지만 중요)

**요구사항**:
- 강력한 추론 능력
- 긴 컨텍스트 처리
- 구조화된 복잡한 출력

## 2026년 최신 모델 추천

### SIMPLE 작업용 모델

#### 1순위: **SmolLM2:1.7B** (또는 360M)
- **이유**: 
  - 초고속 추론 (135M-1.7B 파라미터)
  - 구조화된 출력에 최적화
  - 8K 컨텍스트로 충분
  - 메모리 효율적 (1.8GB)
- **사용 모델**: `smollm2:1.7b` 또는 `smollm2:360m`
- **예상 속도**: 매우 빠름 (100-300ms)
- **정확도**: 간단한 작업에 충분

#### 2순위: **Phi-3:3.8B**
- **이유**:
  - Microsoft의 경량 모델
  - 작은 크기지만 성능 우수
  - 구조화된 출력 지원
- **사용 모델**: `phi3:3.8b`
- **예상 속도**: 빠름 (200-500ms)

#### 3순위: **Mistral 7B**
- **이유**:
  - 빠른 추론 (20-30% 더 빠름)
  - 범용적 성능
- **사용 모델**: `mistral:7b`
- **예상 속도**: 빠름 (300-600ms)

### MEDIUM 작업용 모델

#### 1순위: **Llama 3.1:8B**
- **이유**:
  - 범용 작업에 최적화
  - 우수한 판단 능력
  - 8GB RAM으로 실행 가능
  - 안정적인 성능
- **사용 모델**: `llama3.1:8b`
- **예상 속도**: 중간 (500ms-2s)
- **정확도**: 높음

#### 2순위: **Qwen3:8B**
- **이유**:
  - 추론 성능 우수
  - 다국어 지원
  - 현재 사용 중인 모델과 일관성
- **사용 모델**: `qwen3:8b`
- **예상 속도**: 중간 (600ms-2s)

#### 3순위: **Mistral 7B**
- **이유**:
  - 빠른 속도
  - 효율적인 리소스 사용
- **사용 모델**: `mistral:7b`

### COMPLEX 작업용 모델

#### 1순위: **Qwen3:14B** (또는 8B)
- **이유**:
  - 복잡한 추론에 강함
  - 긴 컨텍스트 처리 (41K 토큰)
  - 구조화된 출력 생성 능력
  - 현재 사용 중인 모델과 일관성
- **사용 모델**: `qwen3:14b` (또는 `qwen3:8b`)
- **예상 속도**: 느림 (2-10s)
- **정확도**: 매우 높음

#### 2순위: **Llama 3.1:70B** (리소스 여유 시)
- **이유**:
  - 매우 강력한 추론 능력
  - 엔터프라이즈급 성능
  - 깊은 분석 가능
- **사용 모델**: `llama3.1:70b`
- **예상 속도**: 매우 느림 (5-30s)
- **리소스**: 32GB+ RAM 필요

#### 3순위: **Llama 3.1:8B**
- **이유**:
  - 리소스 제약 시 좋은 절충안
  - 여전히 좋은 성능
- **사용 모델**: `llama3.1:8b`

## 최종 추천 구성

### 구성 A: 균형잡힌 구성 (권장)
```
SIMPLE:  smollm2:1.7b      (빠르고 효율적)
MEDIUM:  llama3.1:8b       (범용적, 안정적)
COMPLEX: qwen3:14b         (강력한 추론)
```

### 구성 B: 속도 우선
```
SIMPLE:  smollm2:360m      (초고속)
MEDIUM:  mistral:7b        (빠름)
COMPLEX: qwen3:8b          (빠른 추론)
```

### 구성 C: 성능 우선
```
SIMPLE:  phi3:3.8b         (작지만 강력)
MEDIUM:  llama3.1:8b      (안정적)
COMPLEX: llama3.1:70b      (최고 성능, 리소스 많이 필요)
```

### 구성 D: 현재 구성 유지 (일관성)
```
SIMPLE:  qwen3:8b          (현재 사용 중)
MEDIUM:  qwen3:8b          (현재 사용 중)
COMPLEX: qwen3:8b          (현재 사용 중)
```

## 모델별 리소스 요구사항

| 모델 | RAM 필요 | 디스크 | 추론 속도 |
|------|----------|--------|-----------|
| smollm2:360m | 1GB | 726MB | 매우 빠름 |
| smollm2:1.7b | 2GB | 1.8GB | 매우 빠름 |
| phi3:3.8b | 4GB | ~2GB | 빠름 |
| mistral:7b | 8GB | ~4GB | 빠름 |
| llama3.1:8b | 8GB | ~4.5GB | 중간 |
| qwen3:8b | 8GB | ~5GB | 중간 |
| qwen3:14b | 16GB | ~8GB | 느림 |
| llama3.1:70b | 32GB+ | ~40GB | 매우 느림 |

## 선택 가이드

1. **리소스가 제한적** → 구성 B (속도 우선)
2. **균형잡힌 성능** → 구성 A (권장)
3. **최고 성능 필요** → 구성 C (성능 우선)
4. **현재 구성 유지** → 구성 D (일관성)

## 마이그레이션 고려사항

- 각 모델은 다른 출력 형식을 가질 수 있으므로 테스트 필요
- 프롬프트 튜닝이 필요할 수 있음
- 모델별 성능 벤치마크 권장
